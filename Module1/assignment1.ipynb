{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 - Word Frequencies\n",
    "\n",
    "Kevin Nolasco\n",
    "\n",
    "Cabrini University\n",
    "\n",
    "MCIS565 - Natural Language Processing\n",
    "\n",
    "03/27/2022\n",
    "\n",
    "# Purpose\n",
    "\n",
    "The purpose of this notebook is to get some practice with the nltk package. We will find the top 50 most common words in text2 of nltk.book.\n",
    "\n",
    "The code below is based on [the NLTK textbook.](https://www.nltk.org/book/ch01.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import text 2\n",
    "from nltk.book import text2, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 9397),\n",
       " ('to', 4063),\n",
       " ('.', 3975),\n",
       " ('the', 3861),\n",
       " ('of', 3565),\n",
       " ('and', 3350),\n",
       " ('her', 2436),\n",
       " ('a', 2043),\n",
       " ('I', 2004),\n",
       " ('in', 1904),\n",
       " ('was', 1846),\n",
       " ('it', 1568),\n",
       " ('\"', 1506),\n",
       " (';', 1419),\n",
       " ('she', 1333),\n",
       " ('be', 1305),\n",
       " ('that', 1297),\n",
       " ('for', 1234),\n",
       " ('not', 1212),\n",
       " ('as', 1179),\n",
       " ('you', 1037),\n",
       " ('with', 971),\n",
       " ('had', 969),\n",
       " ('his', 941),\n",
       " ('he', 895),\n",
       " (\"'\", 883),\n",
       " ('have', 807),\n",
       " ('at', 806),\n",
       " ('by', 737),\n",
       " ('is', 728),\n",
       " ('.\"', 721),\n",
       " ('s', 700),\n",
       " ('Elinor', 684),\n",
       " ('on', 676),\n",
       " ('all', 642),\n",
       " ('him', 633),\n",
       " ('so', 617),\n",
       " ('but', 597),\n",
       " ('which', 592),\n",
       " ('could', 568),\n",
       " ('Marianne', 566),\n",
       " ('my', 551),\n",
       " ('Mrs', 530),\n",
       " ('from', 527),\n",
       " ('would', 507),\n",
       " ('very', 492),\n",
       " ('no', 488),\n",
       " ('their', 463),\n",
       " ('them', 462),\n",
       " ('--', 461)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = FreqDist(text2)\n",
    "word_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like some of the most common \"words\" are punctuations. Let's try to remove those using regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def most_common_words_only(freqs):\n",
    "    actual_list = []\n",
    "    for word in freqs:\n",
    "        # check for no punctuations\n",
    "        if not bool(re.search(r'[^\\w\\s]', word)):\n",
    "            actual_list.append((word, freqs[word]))\n",
    "    return actual_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 4063),\n",
       " ('the', 3861),\n",
       " ('of', 3565),\n",
       " ('and', 3350),\n",
       " ('her', 2436),\n",
       " ('a', 2043),\n",
       " ('I', 2004),\n",
       " ('in', 1904),\n",
       " ('was', 1846),\n",
       " ('it', 1568),\n",
       " ('she', 1333),\n",
       " ('be', 1305),\n",
       " ('that', 1297),\n",
       " ('for', 1234),\n",
       " ('not', 1212),\n",
       " ('as', 1179),\n",
       " ('you', 1037),\n",
       " ('with', 971),\n",
       " ('had', 969),\n",
       " ('his', 941),\n",
       " ('he', 895),\n",
       " ('have', 807),\n",
       " ('at', 806),\n",
       " ('by', 737),\n",
       " ('is', 728),\n",
       " ('s', 700),\n",
       " ('Elinor', 684),\n",
       " ('on', 676),\n",
       " ('all', 642),\n",
       " ('him', 633),\n",
       " ('so', 617),\n",
       " ('but', 597),\n",
       " ('which', 592),\n",
       " ('could', 568),\n",
       " ('Marianne', 566),\n",
       " ('my', 551),\n",
       " ('Mrs', 530),\n",
       " ('from', 527),\n",
       " ('would', 507),\n",
       " ('very', 492),\n",
       " ('no', 488),\n",
       " ('their', 463),\n",
       " ('them', 462),\n",
       " ('been', 440),\n",
       " ('were', 437),\n",
       " ('me', 433),\n",
       " ('they', 428),\n",
       " ('more', 406),\n",
       " ('said', 397),\n",
       " ('any', 389)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_common_words = most_common_words_only(word_freq)\n",
    "actual_common_words[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see the distribution we are interested in! These are only words without punctuations."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c40c1a4a39d26129282935a5bbc78efbeaeaa8764651d7ab4d2f67e39ab82a95"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
