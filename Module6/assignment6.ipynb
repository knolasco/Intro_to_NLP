{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building with First Order Logic\n",
    "\n",
    "Kevin Nolasco\n",
    "\n",
    "Cabrini University\n",
    "\n",
    "MCIS565 - Natural Language Processing\n",
    "\n",
    "05/01/2022\n",
    "\n",
    "## Prompt\n",
    "\n",
    "Select three or four contiguous sentences from a book for children. A possible source of examples are the collections of stories in nltk.corpus.gutenberg: bryant-stories.txt, burgess-busterbrown.txt and edgeworth-parents.txt. Develop a grammar which will allow your sentences to be translated into first order logic, and build a model which will allow those translations to be checked for truth or falsity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We will use nltk.corpus.gutenberg to load our sentences. Then we will peak at the first 20 sentences to find 3 that would work well for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "all_sents = nltk.corpus.gutenberg.sents('bryant-stories.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2863\n",
      "0 ['[', 'Stories', 'to', 'Tell', 'to', 'Children', 'by', 'Sara', 'Cone', 'Bryant', '1918', ']']\n",
      "1 ['TWO', 'LITTLE', 'RIDDLES', 'IN', 'RHYME']\n",
      "2 ['There', \"'\", 's', 'a', 'garden', 'that', 'I', 'ken', ',', 'Full', 'of', 'little', 'gentlemen', ';', 'Little', 'caps', 'of', 'blue', 'they', 'wear', ',', 'And', 'green', 'ribbons', ',', 'very', 'fair', '.']\n",
      "3 ['(', 'Flax', '.)']\n",
      "4 ['From', 'house', 'to', 'house', 'he', 'goes', ',', 'A', 'messenger', 'small', 'and', 'slight', ',', 'And', 'whether', 'it', 'rains', 'or', 'snows', ',', 'He', 'sleeps', 'outside', 'in', 'the', 'night', '.']\n",
      "5 ['(', 'The', 'path', '.)']\n",
      "6 ['THE', 'LITTLE', 'YELLOW', 'TULIP']\n",
      "7 ['Once', 'there', 'was', 'a', 'little', 'yellow', 'Tulip', ',', 'and', 'she', 'lived', 'down', 'in', 'a', 'little', 'dark', 'house', 'under', 'the', 'ground', '.']\n",
      "8 ['One', 'day', 'she', 'was', 'sitting', 'there', ',', 'all', 'by', 'herself', ',', 'and', 'it', 'was', 'very', 'still', '.']\n",
      "9 ['Suddenly', ',', 'she', 'heard', 'a', 'little', '_tap', ',', 'tap', ',', 'tap_', ',', 'at', 'the', 'door', '.']\n",
      "10 ['\"', 'Who', 'is', 'that', '?\"']\n",
      "11 ['she', 'said', '.']\n",
      "12 ['\"', 'It', \"'\", 's', 'the', 'Rain', ',', 'and', 'I', 'want', 'to', 'come', 'in', ',\"', 'said', 'a', 'soft', ',', 'sad', ',', 'little', 'voice', '.']\n",
      "13 ['\"', 'No', ',', 'you', 'can', \"'\", 't', 'come', 'in', ',\"', 'the', 'little', 'Tulip', 'said', '.']\n",
      "14 ['By', 'and', 'by', 'she', 'heard', 'another', 'little', '_tap', ',', 'tap', ',', 'tap_', 'on', 'the', 'window', '-', 'pane', '.']\n",
      "15 ['\"', 'Who', 'is', 'there', '?\"']\n",
      "16 ['she', 'said', '.']\n",
      "17 ['The', 'same', 'soft', 'little', 'voice', 'answered', ',', '\"', 'It', \"'\", 's', 'the', 'Rain', ',', 'and', 'I', 'want', 'to', 'come', 'in', '!\"']\n",
      "18 ['\"', 'No', ',', 'you', 'can', \"'\", 't', 'come', 'in', ',\"', 'said', 'the', 'little', 'Tulip', '.']\n",
      "19 ['Then', 'it', 'was', 'very', 'still', 'for', 'a', 'long', 'time', '.']\n"
     ]
    }
   ],
   "source": [
    "print(len(all_sents))\n",
    "for ind ,sents in enumerate(all_sents[:20]):\n",
    "    print(ind, sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the first 20 sentences, we can see that sentences 7,8 and 9 are good sentences to use for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Once', 'there', 'was', 'a', 'little', 'yellow', 'Tulip', ',', 'and', 'she', 'lived', 'down', 'in', 'a', 'little', 'dark', 'house', 'under', 'the', 'ground', '.']\n",
      "['One', 'day', 'she', 'was', 'sitting', 'there', ',', 'all', 'by', 'herself', ',', 'and', 'it', 'was', 'very', 'still', '.']\n",
      "['Suddenly', ',', 'she', 'heard', 'a', 'little', '_tap', ',', 'tap', ',', 'tap_', ',', 'at', 'the', 'door', '.']\n"
     ]
    }
   ],
   "source": [
    "sentences_to_use = all_sents[7:10]\n",
    "for sent in sentences_to_use:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "We will remove punctuations and the underscores that are attached to \"tap\" before moving on to building the grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Once', 'there', 'was', 'a', 'little', 'yellow', 'Tulip', 'and', 'she', 'lived', 'down', 'in', 'a', 'little', 'dark', 'house', 'under', 'the', 'ground']\n",
      "['One', 'day', 'she', 'was', 'sitting', 'there', 'all', 'by', 'herself', 'and', 'it', 'was', 'very', 'still']\n",
      "['Suddenly', 'she', 'heard', 'a', 'little', 'tap', 'at', 'the', 'door']\n"
     ]
    }
   ],
   "source": [
    "# remove punctuations\n",
    "cleaned_sentences = [[word for word in sent if word.isalpha()] for sent in sentences_to_use]\n",
    "for sent in cleaned_sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence 1\n",
    "\n",
    "Before creating the grammar for sentence 1, let's determine how we can simplify the information given in sentence 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once there was a little yellow Tulip and she lived down in a little dark house under the ground'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = cleaned_sentences[0]\n",
    "' '.join(sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize the information given in the sentence above as \"The little yellow Tulip lives in a little dark house.\"\n",
    "\n",
    "I want the logic for this sentence to be:\n",
    "\n",
    "\"There exists a Tulip that is little and yellow and there exists a house that is little and dark and the the Tulip lives in the house.\"\n",
    "\n",
    "Using first-order logic, this could be:\n",
    "\n",
    "$\\left[\\exists t.(Tulip(t) \\& little(t) \\& yellow(t)) \\rightarrow \\exists h.((House(h) \\& little(h) \\& dark(h)) \\& lives(t, h)) \\right]$\n",
    "\n",
    "Which translates to \"if (there exists a tulip that is little and yellow) then (there exists a house that is little and dark and the tulip lives in the house)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the POS for the words used in the summarized sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'DT')\n",
      "('little', 'JJ')\n",
      "('yellow', 'JJ')\n",
      "('Tulip', 'NNP')\n",
      "('lives', 'VBZ')\n",
      "('in', 'IN')\n",
      "('a', 'DT')\n",
      "('little', 'JJ')\n",
      "('dark', 'NN')\n",
      "('house', 'NN')\n"
     ]
    }
   ],
   "source": [
    "simple_sent_1 = \"\"\"\n",
    "The little yellow Tulip lives in a little dark house\n",
    "\"\"\"\n",
    "simple_sent_1_tokenized = simple_sent_1.split()\n",
    "for item in nltk.pos_tag(simple_sent_1_tokenized):\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the grammar below is saved as a .fcfg file in the current directory\n",
    "grammar = r\"\"\"\n",
    "% start S\n",
    "# Grammar Rules\n",
    "S[SEM = <?subj(?vp)>] -> NP[SEM=?subj] VP[SEM=?vp]\n",
    "NP[SEM=<?dt(?jj, ?jj, ?nnp)>] -> DT[SEM=?dt] JJ[SEM=?jj] JJ[SEM=?jj] NNP[SEM=?nnp]\n",
    "NP[SEM=<?jj(?nn, ?nn)>] -> JJ[SEM=?jj] NN[SEM=?nn] NN[SEM=?nn]\n",
    "VP[SEM=<?vbz(?pp, ?np)>] -> VBZ[SEM=<?vbz>] PP[SEM=?pp] NP[SEM=?np]\n",
    "PP[SEM=?dt] -> IN DT[SEM=?dt]\n",
    "# Lexical Rules\n",
    "DT[SEM=<\\P Q R S.(exists x.((R(x) & P(x) & Q(x)) -> (S)))>] -> 'The'\n",
    "JJ[SEM=<\\x.little(x)>] -> 'little'\n",
    "JJ[SEM=<\\x.yellow(x)>] -> 'yellow'\n",
    "NNP[SEM=<\\x.Tulip(x)>] -> 'Tulip'\n",
    "VBZ[SEM=<\\P.(P & lives(x, y))>] -> 'lives'\n",
    "IN -> 'in'\n",
    "DT[SEM=<\\P Q R.(exists y.(R(y) & P(y) & Q(y)))>] -> 'a'\n",
    "NN[SEM=<\\x.dark(x)>] -> 'dark'\n",
    "NN[SEM=<\\x.House(x)>] -> 'house'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.parse.load_parser('grammar1.fcfg', trace = 0)\n",
    "for tree in parser.parse(simple_sent_1_tokenized):\n",
    "    print(tree.label()['SEM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be some results here, but the parser is not parsing the sentence correctly and I am not sure how to fix this. Since the sentence can't be parsed correctly, I cannot complete the remaining parts of the assignment."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2356144fe0ac51fab68dc1c6bfa977c118efc9fe44eaadb7d7a066f16e6a87e4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
