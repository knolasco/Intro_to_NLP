{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Taggers with NLTK\n",
    "\n",
    "Kevin Nolasco\n",
    "\n",
    "Cabrini University\n",
    "\n",
    "MCIS565 - Natural Language Processing\n",
    "\n",
    "04/10/2022\n",
    "\n",
    "\n",
    "## Prompt\n",
    "- Create a regular expression tagger and various unigram and n-gram taggers, incorporating backoff, and train them on part of the Brown corpus.\n",
    "- Create three different combinations of the taggers. Test the accuracy of each combined tagger. Which combination works best?\n",
    "- Try varying the size of the training corpus. How does it affect your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regexp Tagger, Various Unigram and N-gram Taggers and Backoff\n",
    "\n",
    "*Create a regular expression tagger and various unigram and n-gram taggers, incorporating backoff, and train them on part of the Brown corpus.*\n",
    "\n",
    "Below we will implement the as for part 1 of the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tagged_sents = brown.tagged_sents(categories = 'news')\n",
    "brown_sents = brown.sents(categories = 'news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train and test\n",
    "def split_sents(tagged_sents, sents, train_size = 0.6):\n",
    "    \"\"\"\n",
    "    return train_tagged_sents, test_tagged_sents, train_sents, test_sents\n",
    "    \"\"\"\n",
    "    train_n = int(len(tagged_sents)*train_size)\n",
    "    return tagged_sents[:train_n], tagged_sents[train_n:], sents[:train_n], sents[train_n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tagged_sents, test_tagged_sents, train_sents, test_sents = split_sents(brown_tagged_sents, brown_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 20.62%\n"
     ]
    }
   ],
   "source": [
    "# make patterns for regex tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),                # gerunds\n",
    "    (r'.*ed$', 'VBD'),                 # simple past\n",
    "    (r'.*es$', 'VBZ'),                 # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),                # modals\n",
    "    (r'.*\\'s$', 'NN$'),                # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                  # plural nouns\n",
    "    (r'^-?[0-9]+(\\.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "    (r'.*', 'NN')                      # nouns (default)\n",
    "]\n",
    "\n",
    "regex_tagger = nltk.RegexpTagger(patterns)\n",
    "regex_tagger.tag(train_sents[0])\n",
    "# .evualuate() is depricated, use accuracy instead\n",
    "print('Accuracy on test set: {:.2%}'.format(regex_tagger.accuracy(train_tagged_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 78.14%\n"
     ]
    }
   ],
   "source": [
    "# quick train and test on tagged sents\n",
    "unigram_tagger = nltk.UnigramTagger(train_tagged_sents)\n",
    "print('Accuracy on test set: {:.2%}'.format(unigram_tagger.accuracy(test_tagged_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 8.37%\n"
     ]
    }
   ],
   "source": [
    "bigram_tagger = nltk.BigramTagger(train_tagged_sents)\n",
    "print('Accuracy on test set: {:.2%}'.format(bigram_tagger.accuracy(test_tagged_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigram Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 5.35%\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(train_tagged_sents)\n",
    "print('Accuracy on test set: {:.2%}'.format(trigram_tagger.accuracy(test_tagged_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 81.43%\n"
     ]
    }
   ],
   "source": [
    "with_backoff = nltk.UnigramTagger(train_tagged_sents, backoff = nltk.DefaultTagger('NN'))\n",
    "print('Accuracy on test set: {:.2%}'.format(with_backoff.accuracy(test_tagged_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Combinations of Taggers\n",
    "\n",
    "*Create three different combinations of the taggers. Test the accuracy of each combined tagger. Which combination works best?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combo 1** will be unigram tagger with regexp as backoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 83.75%\n"
     ]
    }
   ],
   "source": [
    "# combo 1 \n",
    "regex_backoff = nltk.UnigramTagger(train_tagged_sents, backoff = nltk.RegexpTagger(patterns))\n",
    "print('Accuracy on test set: {:.2%}'.format(regex_backoff.accuracy(test_tagged_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combo 2** will be unigram tagger with regexp as backoff and with default tagger as backoff for regexp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 83.75%\n"
     ]
    }
   ],
   "source": [
    "# combo 2\n",
    "combo2 = nltk.UnigramTagger(train_tagged_sents, backoff = nltk.RegexpTagger(patterns, backoff = nltk.DefaultTagger('NN')))\n",
    "print('Accuracy on test set: {:.2%}'.format(combo2.accuracy(test_tagged_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combo 3** will be bigram tagger with unigram as backoff and with regexp tagger as backoff for unigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 84.50%\n"
     ]
    }
   ],
   "source": [
    "# combo 3\n",
    "combo3 = nltk.BigramTagger(train_tagged_sents, backoff = nltk.UnigramTagger(train_tagged_sents, backoff = nltk.RegexpTagger(patterns)))\n",
    "print('Accuracy on test set: {:.2%}'.format(combo3.accuracy(test_tagged_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Combo** will be trigram tagger with combo 3 as the backoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 84.44%\n"
     ]
    }
   ],
   "source": [
    "# combo 4\n",
    "combo4 = nltk.TrigramTagger(train_tagged_sents, backoff = nltk.BigramTagger(train_tagged_sents, backoff = nltk.UnigramTagger(train_tagged_sents, backoff = nltk.RegexpTagger(patterns))))\n",
    "print('Accuracy on test set: {:.2%}'.format(combo4.accuracy(test_tagged_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Combo 3 was the most accurate tagger. This goes along with what the textbook was saying about \"[As n gets larger, the specificity of the contexts increases, as does the chance that the data we wish to tag contains contexts that were not present in the training data. This is known as the sparse data problem, and is quite pervasive in NLP. As a consequence, there is a trade-off between the accuracy and the coverage of our results (and this is related to the precision/recall trade-off in information retrieval).](https://www.nltk.org/book/ch05.html#:~:text=As%20n%20gets,in%20information%20retrieval)\". This implies that if we continue stacking the backoffs like above, the performance will not improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Varying Size \n",
    "\n",
    "*Try varying the size of the training corpus. How does it affect your results?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def train_size_increase():\n",
    "    for train_size in np.arange(0.65,1, 0.05):\n",
    "        train_tagged_sents, test_tagged_sents, _, _ = split_sents(brown_tagged_sents, brown_sents, train_size = train_size)\n",
    "        tagger = nltk.BigramTagger(train_tagged_sents, backoff = nltk.UnigramTagger(train_tagged_sents, backoff = nltk.RegexpTagger(patterns)))\n",
    "        print('=============================================================================\\n')\n",
    "        print('For train size = {:.0%}'.format(train_size))\n",
    "        print('Accuracy on test set: {:.2%}'.format(tagger.accuracy(test_tagged_sents)))\n",
    "        print('\\n=============================================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================\n",
      "\n",
      "For train size = 65%\n",
      "Accuracy on test set: 84.81%\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "For train size = 70%\n",
      "Accuracy on test set: 85.51%\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "For train size = 75%\n",
      "Accuracy on test set: 86.05%\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "For train size = 80%\n",
      "Accuracy on test set: 85.81%\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "For train size = 85%\n",
      "Accuracy on test set: 86.56%\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "For train size = 90%\n",
      "Accuracy on test set: 86.50%\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "=============================================================================\n",
      "\n",
      "For train size = 95%\n",
      "Accuracy on test set: 88.47%\n",
      "\n",
      "=============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_size_increase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the best accuracy on test set comes from training it with 95% of the data. This makes sense because we know that for every project, lots of data is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Above we can see the implementation of different taggers on the Brown corpus. We can see that N-Gram taggers are a powerful tool and that for this situation, a Bigram Tagger was most effective. We can see that the training size impacts the accuracy score, so presenting the taggers with lots of good data is important."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bed9e8efb48b808a3abfd6983aa1cb26fcee098209d0c711d12f130c994306c3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
